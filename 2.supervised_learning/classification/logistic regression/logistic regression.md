In linear regression, (the independent variables) are used to estimate the specific value of (the dependent variable).

in simple terms it is used to create a line of perfect fit to the data to predict the values.

on the other hand logistic regression predicts the probability that a specific outcome occurs. For instance, given someone’s financial profile, we might predict the probability that their loan is approved. The output of the model is a value between 0 and 1. Based on a threshold—often 0.5—we classify the outcome as either "approved" or "not approved.

logistic regression fits an S-shaped curve to map input values to a probability.

this will be explained mathematically in detail. 

### why are we calling a classification model the Logistic ‘Regression’?

The reason behind this is that just like Linear Regression, logistic regression starts from a linear equation. However, this equation consists of log-odds which is further passed through a sigmoid function which squeezes the output of the linear equation to a probability between 0 and 1. And, we can decide a decision boundary and use this probability to conduct classification task.

### Example: logistic Regression Model

WIP

---

## mathematical explanation:

----

